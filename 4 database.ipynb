{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo su \n",
    "#apt-get update\n",
    "#apt-get install openjdk-8-jdk-headless -qq > /dev/null \n",
    "#wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
    "#tar xf spark-3.2.1-bin-hadoop3.2.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6da5c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "import pyspark\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc987041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting environment variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"spark-3.2.1-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd5b3323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cube-4f596e19-3c7b-4e6b-8d22-c8935b16d77b-76b7dc5d58-bklmj:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark App</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f67c92499a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark App\") \\\n",
    "    .config(\"spark.jars\", \"jar_files/postgresql-42.3.2.jar\") \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27414332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Spark and SQL context\n",
    "sparkcontext = pyspark.SparkContext.getOrCreate()\n",
    "sqlcontext = SQLContext(sparkcontext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3d23864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting database parameters\n",
    "postgres_uri = \"jdbc:postgresql://depgdb.crhso94tou3n.eu-west-2.rds.amazonaws.com:5432/claragoebel21\"\n",
    "user = \"claragoebel21\"\n",
    "password = \"qwerty123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4813f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data\n",
    "df = pd.read_csv(\"output_data/data_vf.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6d3be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions to read from or write to database\n",
    "def read_db(db_table):\n",
    "    try:\n",
    "        df_spark = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", postgres_uri) \\\n",
    "        .option(\"dbtable\", db_table) \\\n",
    "        .option(\"user\", user) \\\n",
    "        .option(\"password\", password) \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .load()\n",
    "        return df_spark\n",
    "    except Exception as ex:\n",
    "        return ex\n",
    "\n",
    "def write_to_db(df_spark, db_table):\n",
    "    try:\n",
    "        df_spark.write \\\n",
    "        .mode(\"append\") \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", postgres_uri) \\\n",
    "        .option(\"dbtable\", db_table) \\\n",
    "        .option(\"user\", user) \\\n",
    "        .option(\"password\", password) \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .save()\n",
    "    except Exception as ex:\n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9b7c85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to clear table in database\n",
    "def truncate_db_table(df_spark, db_table):\n",
    "    df_spark.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"cascadeTruncate\", True) \\\n",
    "    .option(\"url\", postgres_uri) \\\n",
    "    .option(\"dbtable\", db_table) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0c2f5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "df_pandas = pd.DataFrame(data = df[\"type\"].unique(), columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "036c2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "df_pandas = pd.DataFrame(data = df[\"source\"].unique(), columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e6629544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "df_pandas = df[[\"postcode\",\n",
    "                \"lat\",\n",
    "                \"long\",\n",
    "                \"pop_density\",\n",
    "                \"public_transport_accessibility\",\n",
    "                \"mean_income\"]].drop_duplicates()\n",
    "df_pandas.columns = [\"postcode\",\n",
    "                     \"latitude\",\n",
    "                     \"longitude\",\n",
    "                     \"population_density\",\n",
    "                     \"pt_accessibility\",\n",
    "                     \"mean_income\"]\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.postcodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4529fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "types = ['ages_0_15', 'ages_16_29', 'ages_30_44', 'ages_45_65', 'ages_66_plus']\n",
    "df_pandas = pd.DataFrame(data = types, columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.pcd_age_bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3a6e2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "types = ['couple_children_dependent', 'couple_children_nondependent', 'lone_parent', 'single', 'other_multi']\n",
    "df_pandas = pd.DataFrame(data = types, columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.pcd_household_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8c25d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "types = ['owned_outright', 'owned_mortgage', 'rented_social', 'rented_private']\n",
    "df_pandas = pd.DataFrame(data = types, columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.pcd_dwelling_ownership\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "70ed6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "types = ['usual_residents', 'nonusual_residents']\n",
    "df_pandas = pd.DataFrame(data = types, columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.pcd_resident_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d978e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "types = ['house_detached', 'house_semidetached', 'house_terraced', 'flat']\n",
    "df_pandas = pd.DataFrame(data = types, columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.pcd_dwelling_types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7bd8accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "types = ['economic_inactive', 'employee', 'self-employed', 'unemployed', 'student']\n",
    "df_pandas = pd.DataFrame(data = types, columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.pcd_economic_activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2b42cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "types = ['unqualified', 'level_1', 'level_2', 'apprenticeship', 'level_3', 'level_4', 'other']\n",
    "df_pandas = pd.DataFrame(data = types, columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.pcd_education_level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b14d0eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "types = ['good_health', 'fair_health', 'bad_health']\n",
    "df_pandas = pd.DataFrame(data = types, columns = [\"name\"])\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.pcd_health_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "810e8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "foreign_key_map = read_db(\"rental_schema.postcodes\").toPandas()\n",
    "foreign_key_map = foreign_key_map[[\"id\", \"postcode\"]]\n",
    "foreign_key_map = {postcode: value for value, postcode in zip(foreign_key_map[\"id\"], foreign_key_map[\"postcode\"])}\n",
    "\n",
    "df_pandas = df[[\"address\", \"postcode\"]].drop_duplicates()\n",
    "df_pandas[\"postcode\"] = df_pandas[\"postcode\"].map(foreign_key_map)\n",
    "df_pandas.columns = [\"full_address\", \"postcode_id\"]\n",
    "\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c40472f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to write many-to-many postcode to category share tables to database\n",
    "def pcd_share_write_to_db(cat_table, df_columns, cat_id_column, share_table):\n",
    "    foreign_key_map_pcd = read_db(\"rental_schema.postcodes\").toPandas()\n",
    "    foreign_key_map_pcd = foreign_key_map_pcd[[\"id\", \"postcode\"]]\n",
    "    foreign_key_map_pcd = {postcode: value for value, postcode in zip(foreign_key_map_pcd[\"id\"], foreign_key_map_pcd[\"postcode\"])}\n",
    "\n",
    "    foreign_key_map_cat = read_db(cat_table).toPandas()\n",
    "    foreign_key_map_cat = foreign_key_map_cat[[\"id\", \"name\"]]\n",
    "    foreign_key_map_cat = {name: value for value, name in zip(foreign_key_map_cat[\"id\"], foreign_key_map_cat[\"name\"])}\n",
    "\n",
    "    df_pandas = df[df_columns].drop_duplicates()\n",
    "    df_pandas = pd.melt(df_pandas, id_vars = df_columns[0], value_vars = df_columns[1:])\n",
    "    df_pandas[\"postcode\"] = df_pandas[\"postcode\"].map(foreign_key_map_pcd)\n",
    "    df_pandas[\"variable\"] = df_pandas[\"variable\"].map(foreign_key_map_cat)\n",
    "    df_pandas.columns = [\"postcode_id\", cat_id_column, \"share\"]\n",
    "    \n",
    "    df_spark = spark.createDataFrame(df_pandas)\n",
    "    write_to_db(df_spark, share_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fd4309d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "pcd_share_write_to_db(\"rental_schema.pcd_age_bins\", \n",
    "                      ['postcode', 'ages_0_15', 'ages_16_29', 'ages_30_44', 'ages_45_65', 'ages_66_plus'], \n",
    "                      \"age_bin_id\", \n",
    "                      \"rental_schema.pcd_age_bin_share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "29ee0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "pcd_share_write_to_db(\"rental_schema.pcd_dwelling_ownership\", \n",
    "                      ['postcode', 'couple_children_dependent', 'couple_children_nondependent', 'lone_parent', 'single', 'other_multi'], \n",
    "                      \"dwelling_ownership_id\", \n",
    "                      \"rental_schema.pcd_dwelling_ownership_share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2b95b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "pcd_share_write_to_db(\"rental_schema.pcd_household_types\", \n",
    "                      ['postcode', 'owned_outright', 'owned_mortgage', 'rented_social', 'rented_private'], \n",
    "                      \"household_type_id\", \n",
    "                      \"rental_schema.pcd_household_type_share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1016ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "pcd_share_write_to_db(\"rental_schema.pcd_resident_types\", \n",
    "                      ['postcode', 'usual_residents', 'nonusual_residents'], \n",
    "                      \"resident_type_id\", \n",
    "                      \"rental_schema.pcd_resident_type_share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b86a3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "pcd_share_write_to_db(\"rental_schema.pcd_dwelling_types\", \n",
    "                      ['postcode', 'house_detached', 'house_semidetached', 'house_terraced', 'flat'], \n",
    "                      \"dwelling_type_id\", \n",
    "                      \"rental_schema.pcd_dwelling_type_share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c4b07e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "pcd_share_write_to_db(\"rental_schema.pcd_economic_activity\", \n",
    "                      ['postcode', 'economic_inactive', 'employee', 'self-employed', 'unemployed', 'student'], \n",
    "                      \"economic_activity_id\", \n",
    "                      \"rental_schema.pcd_economic_activity_share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f372277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "pcd_share_write_to_db(\"rental_schema.pcd_education_level\", \n",
    "                      ['postcode', 'unqualified', 'level_1', 'level_2', 'apprenticeship', 'level_3', 'level_4', 'other'], \n",
    "                      \"education_level_id\", \n",
    "                      \"rental_schema.pcd_education_level_share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "41ffbecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to database\n",
    "pcd_share_write_to_db(\"rental_schema.pcd_health_status\", \n",
    "                      ['postcode', 'good_health', 'fair_health', 'bad_health'], \n",
    "                      \"health_status_id\", \n",
    "                      \"rental_schema.pcd_health_status_share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5e531d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-201-e1867fb84c8a>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pandas[\"source\"] = df_pandas[\"source\"].map(foreign_key_map_source)\n",
      "<ipython-input-201-e1867fb84c8a>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pandas[\"address\"] = df_pandas[\"address\"].map(foreign_key_map_address)\n",
      "<ipython-input-201-e1867fb84c8a>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pandas[\"type\"] = df_pandas[\"type\"].map(foreign_key_map_type)\n"
     ]
    }
   ],
   "source": [
    "#Writing to database\n",
    "foreign_key_map_source = read_db(\"rental_schema.sources\").toPandas()\n",
    "foreign_key_map_source = foreign_key_map_source[[\"id\", \"name\"]]\n",
    "foreign_key_map_source = {name: value for value, name in zip(foreign_key_map_source[\"id\"], foreign_key_map_source[\"name\"])}\n",
    "\n",
    "foreign_key_map_address = read_db(\"rental_schema.address\").toPandas()\n",
    "foreign_key_map_address = foreign_key_map_address[[\"id\", \"full_address\"]]\n",
    "foreign_key_map_address = {name: value for value, name in zip(foreign_key_map_address[\"id\"], foreign_key_map_address[\"full_address\"])}\n",
    "\n",
    "foreign_key_map_type = read_db(\"rental_schema.types\").toPandas()\n",
    "foreign_key_map_type = foreign_key_map_type[[\"id\", \"name\"]]\n",
    "foreign_key_map_type = {name: value for value, name in zip(foreign_key_map_type[\"id\"], foreign_key_map_type[\"name\"])}\n",
    "\n",
    "df_pandas = df[[\"bedrooms\", \"bathrooms\", \"nearest_station\", \"price\", \"size_imputed\", \"type\", \"address\", \"source\"]]\n",
    "df_pandas[\"source\"] = df_pandas[\"source\"].map(foreign_key_map_source)\n",
    "df_pandas[\"address\"] = df_pandas[\"address\"].map(foreign_key_map_address)\n",
    "df_pandas[\"type\"] = df_pandas[\"type\"].map(foreign_key_map_type)\n",
    "df_pandas.columns = [\"bedrooms\", \"bathrooms\", \"nearest_station_distance\", \"price\", \"size_imputed\", \"type_id\", \"address_id\", \"source_id\"]\n",
    "\n",
    "df_spark = spark.createDataFrame(df_pandas)\n",
    "write_to_db(df_spark, \"rental_schema.listings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
